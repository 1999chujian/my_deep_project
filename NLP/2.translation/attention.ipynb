{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于注意力机制的翻译系统\n",
    "\n",
    "\n",
    "首先加载依赖的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 英文转汉语\n",
    "\n",
    "之前基于seq2seq的模型，现在加入注意力机制。\n",
    "### 1.1 数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I don't want it.\\t我不要.\", 'I feel relieved.\\t我感觉轻松了。', 'I get up at six.\\t我六點起床。', 'I had no choice.\\t那时我没有选择的余地。', 'I hate studying.\\t我讨厌学习。']\n",
      "英文数据:\n",
      " ['Hi.', 'Hi.', 'Run.', 'Wait!', 'Hello!', 'I try.', 'I won!', 'Oh no!', 'Cheers!', 'He ran.']\n",
      "\n",
      "中文数据:\n",
      " ['嗨。', '你好。', '你用跑的。', '等等！', '你好。', '让我来。', '我赢了。', '不会吧。', '乾杯!', '他跑了。']\n"
     ]
    }
   ],
   "source": [
    "# ========读取原始数据========\n",
    "with open('cmn.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "data = data.split('\\n')\n",
    "data = data[:1000]\n",
    "print(data[-5:])\n",
    "\n",
    "\n",
    "# 分割英文数据和中文数据\n",
    "en_data = [line.split('\\t')[0] for line in data]\n",
    "ch_data = [line.split('\\t')[1] for line in data]\n",
    "print('英文数据:\\n', en_data[:10])\n",
    "print('\\n中文数据:\\n', ch_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "英文字典:\n",
      " {'<PAD>': 0, '<UNK>': 1, 'd': 2, 'j': 3, 'F': 4, '8': 5, 't': 6, 'S': 7, 'w': 8, 'P': 9, 'W': 10, ' ': 11, 'u': 12, '0': 13, 'o': 14, 'r': 15, '3': 16, '!': 17, 'E': 18, ',': 19, 'Q': 20, 'J': 21, 'I': 22, 'a': 23, 'K': 24, 'T': 25, 'f': 26, 's': 27, 'L': 28, 'B': 29, 'k': 30, 'h': 31, '7': 32, 'v': 33, 'q': 34, 'm': 35, ':': 36, 'O': 37, 'c': 38, 'z': 39, '.': 40, 'Y': 41, 'R': 42, 'l': 43, 'e': 44, 'p': 45, \"'\": 46, 'A': 47, 'G': 48, 'b': 49, 'y': 50, 'g': 51, 'x': 52, 'H': 53, 'U': 54, '1': 55, 'C': 56, 'N': 57, '?': 58, 'D': 59, 'V': 60, 'M': 61, 'n': 62, 'i': 63}\n",
      "\n",
      "中文字典共计\n",
      ": {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3, '照': 4, '牢': 5, '存': 6, '學': 7, '他': 8, '认': 9, '说': 10, '溺': 11, '定': 12, '當': 13, '時': 14, '漲': 15, '车': 16, '逝': 17, '赏': 18, '员': 19, '乾': 20, '很': 21, '通': 22, '亲': 23, '指': 24, '聽': 25, '恥': 26, '們': 27, '丽': 28, '谦': 29, '举': 30, '狸': 31, '燃': 32, '矩': 33, '每': 34, '笔': 35, '嘴': 36, '誰': 37, '联': 38, '恨': 39, '對': 40, '斯': 41, '書': 42, '移': 43, '被': 44, '从': 45, '理': 46, '疲': 47, '內': 48, '控': 49, '愉': 50, '逮': 51, '些': 52, '派': 53, '识': 54, '抱': 55, '蛋': 56, '請': 57, '人': 58, '咳': 59, '如': 60, '過': 61, '生': 62, '嗝': 63, '赢': 64, '退': 65, ' ': 66, '货': 67, '後': 68, '金': 69, '三': 70, '消': 71, '一': 72, '3': 73, 'o': 74, '掃': 75, '应': 76, '信': 77, '靜': 78, '该': 79, '！': 80, '睡': 81, 'T': 82, '在': 83, '然': 84, '糟': 85, '慕': 86, '愚': 87, '聲': 88, '来': 89, '虚': 90, '興': 91, '比': 92, '躺': 93, '日': 94, '輕': 95, '？': 96, '運': 97, '后': 98, '留': 99, '对': 100, '憐': 101, '次': 102, '凶': 103, '斷': 104, '用': 105, '管': 106, '說': 107, '尽': 108, '餓': 109, '嘗': 110, '傻': 111, '她': 112, '备': 113, '著': 114, '衬': 115, '長': 116, '点': 117, '施': 118, '往': 119, '嘿': 120, 'r': 121, '降': 122, '樂': 123, '规': 124, '手': 125, '磁': 126, '訴': 127, '铃': 128, '圈': 129, '棒': 130, '怪': 131, '器': 132, '原': 133, '平': 134, '压': 135, '槍': 136, '渴': 137, '緊': 138, '才': 139, '出': 140, '使': 141, '士': 142, '本': 143, '样': 144, '文': 145, '諒': 146, '气': 147, '面': 148, '買': 149, '意': 150, '繼': 151, '動': 152, '四': 153, '訂': 154, '飯': 155, '相': 156, '剧': 157, '材': 158, '戒': 159, '丟': 160, '现': 161, '頓': 162, '票': 163, '始': 164, '静': 165, '少': 166, '孤': 167, '認': 168, '床': 169, '数': 170, '心': 171, '聊': 172, '此': 173, '亡': 174, '解': 175, '客': 176, '決': 177, '进': 178, '息': 179, '頭': 180, '不': 181, '松': 182, '牙': 183, '玩': 184, '待': 185, '愛': 186, '讓': 187, '餐': 188, '房': 189, '蠢': 190, '目': 191, '干': 192, '駛': 193, '示': 194, '裡': 195, '韩': 196, '会': 197, '烟': 198, '望': 199, '前': 200, '建': 201, '之': 202, '爱': 203, '迎': 204, '盛': 205, '啊': 206, '狗': 207, '恭': 208, '閉': 209, '眼': 210, '关': 211, '朋': 212, '神': 213, '跳': 214, '變': 215, '備': 216, '空': 217, '點': 218, '钢': 219, '光': 220, '魚': 221, '間': 222, '門': 223, '價': 224, '难': 225, '忙': 226, '恐': 227, '门': 228, '隻': 229, '鮮': 230, '旗': 231, '以': 232, '论': 233, '抓': 234, '誤': 235, '沉': 236, '博': 237, '怎': 238, '什': 239, '費': 240, '燒': 241, '必': 242, '狐': 243, '奇': 244, '個': 245, '羞': 246, '星': 247, '父': 248, '阅': 249, '正': 250, '保': 251, '師': 252, '份': 253, '迟': 254, '非': 255, '這': 256, '伙': 257, '合': 258, '鬼': 259, '服': 260, '早': 261, '危': 262, '強': 263, '景': 264, '矮': 265, '8': 266, '开': 267, '曲': 268, '准': 269, '碰': 270, '現': 271, '身': 272, '開': 273, '會': 274, '慢': 275, '節': 276, '響': 277, '糕': 278, '证': 279, '!': 280, '贺': 281, '男': 282, '小': 283, '击': 284, '坚': 285, '速': 286, '嗨': 287, '球': 288, '友': 289, '睛': 290, '祝': 291, '火': 292, '单': 293, '无': 294, '里': 295, '7': 296, '几': 297, '還': 298, '路': 299, '更': 300, '密': 301, '把': 302, '漂': 303, '己': 304, '懒': 305, '雾': 306, '楚': 307, '老': 308, '努': 309, '题': 310, '是': 311, '道': 312, '警': 313, '新': 314, '节': 315, '插': 316, '?': 317, '憾': 318, '借': 319, '经': 320, '丢': 321, '車': 322, '淹': 323, '迷': 324, '报': 325, '险': 326, '取': 327, '啡': 328, '我': 329, '捕': 330, '升': 331, '水': 332, '给': 333, '滿': 334, '右': 335, '谎': 336, '湯': 337, '止': 338, '禁': 339, '张': 340, '郵': 341, '呢': 342, '離': 343, '公': 344, '僱': 345, '儿': 346, '明': 347, '归': 348, '图': 349, '怨': 350, '提': 351, '帶': 352, '么': 353, '觉': 354, '饱': 355, '射': 356, '量': 357, '握': 358, '科': 359, '钱': 360, '醫': 361, '職': 362, '它': 363, '希': 364, '白': 365, '万': 366, '功': 367, '持': 368, '诉': 369, '找': 370, '别': 371, '趣': 372, '美': 373, '死': 374, '嗽': 375, '別': 376, '聞': 377, '力': 378, '張': 379, '拒': 380, '遠': 381, '沒': 382, '间': 383, '缺': 384, 't': 385, '月': 386, '眉': 387, '个': 388, '胶': 389, '能': 390, '巴': 391, '怕': 392, '常': 393, '脸': 394, '影': 395, '游': 396, '趴': 397, '甜': 398, '魯': 399, '到': 400, '進': 401, '机': 402, '动': 403, '评': 404, '愿': 405, '為': 406, '烤': 407, '腾': 408, '業': 409, '耐': 410, '笑': 411, '弄': 412, '付': 413, '無': 414, '安': 415, '話': 416, '佬': 417, '臂': 418, '懂': 419, '命': 420, '波': 421, '只': 422, '拿': 423, '累': 424, '責': 425, '再': 426, '棄': 427, '瓦': 428, '塗': 429, '罪': 430, '易': 431, '塊': 432, '泳': 433, '坐': 434, '瘋': 435, '同': 436, '幾': 437, '大': 438, '迅': 439, '家': 440, '武': 441, '麼': 442, '鸟': 443, '烦': 444, '跑': 445, '听': 446, '地': 447, '玛': 448, '醉': 449, '勇': 450, '让': 451, '赶': 452, '哈': 453, '加': 454, '歡': 455, '全': 456, '羡': 457, '梦': 458, '高': 459, '識': 460, '倦': 461, '酸': 462, '擊': 463, '弃': 464, '工': 465, '見': 466, '遗': 467, '告': 468, '電': 469, '貪': 470, '盯': 471, '作': 472, '搅': 473, '完': 474, '魂': 475, '色': 476, '叫': 477, '粗': 478, '給': 479, '尊': 480, '妻': 481, '穷': 482, '傷': 483, '孕': 484, '糖': 485, '烧': 486, '就': 487, '东': 488, '杯': 489, '親': 490, '默': 491, '匈': 492, '習': 493, '歉': 494, '天': 495, '疼': 496, '可': 497, 'w': 498, '年': 499, '錯': 500, '快': 501, '国': 502, '酒': 503, '獨': 504, '衣': 505, '参': 506, '刚': 507, '习': 508, '条': 509, '雨': 510, '拥': 511, '鬆': 512, 'J': 513, '玫': 514, '辦': 515, '改': 516, '饿': 517, '重': 518, '饭': 519, '困': 520, '还': 521, '洗': 522, '駕': 523, '最': 524, '鄙': 525, '妒': 526, '候': 527, 'm': 528, '唱': 529, '貴': 530, '十': 531, '欣': 532, '切': 533, '念': 534, '按': 535, '停': 536, '遲': 537, '匙': 538, '鳥': 539, '婪': 540, '箱': 541, '兴': 542, '祈': 543, '耳': 544, '閱': 545, '吻': 546, '等': 547, '你': 548, '噢': 549, '请': 550, '入': 551, '禱': 552, '狂': 553, '趕': 554, '擦': 555, '清': 556, '确': 557, '响': 558, '嗎': 559, '性': 560, '結': 561, '盡': 562, '圆': 563, '了': 564, '住': 565, '系': 566, '怀': 567, '雪': 568, '稍': 569, '谓': 570, '接': 571, '聰': 572, '乐': 573, '紧': 574, '轻': 575, '中': 576, '溜': 577, '热': 578, '置': 579, '任': 580, '方': 581, '假': 582, '包': 583, '筆': 584, '运': 585, '帝': 586, '期': 587, '惜': 588, '，': 589, '賣': 590, '1': 591, '续': 592, '汤': 593, '飛': 594, '哪': 595, '續': 596, '电': 597, '圖': 598, '食': 599, '随': 600, '挥': 601, '菜': 602, '忘': 603, '兒': 604, '奋': 605, '助': 606, '吧': 607, '險': 608, '起': 609, '吸': 610, '视': 611, '壞': 612, '冒': 613, '搞': 614, '活': 615, '哭': 616, '偷': 617, '六': 618, '受': 619, '选': 620, '校': 621, '成': 622, '救': 623, '敗': 624, '鲜': 625, '打': 626, '太': 627, '倖': 628, '蘋': 629, '向': 630, '騙': 631, '何': 632, '辞': 633, '书': 634, '糊': 635, '呆': 636, '激': 637, 'e': 638, '看': 639, '试': 640, '母': 641, '京': 642, '來': 643, 'D': 644, '填': 645, '鱼': 646, '想': 647, '去': 648, '蒼': 649, '知': 650, '孩': 651, '難': 652, '音': 653, '结': 654, '需': 655, '事': 656, '实': 657, '那': 658, '头': 659, '岁': 660, '错': 661, '过': 662, '味': 663, '由': 664, '咖': 665, '世': 666, '您': 667, '木': 668, '露': 669, '煩': 670, '问': 671, '都': 672, '麗': 673, '藏': 674, '尝': 675, '滾': 676, '欠': 677, '醬': 678, '善': 679, '冷': 680, '决': 681, '今': 682, '下': 683, '边': 684, '痛': 685, '醒': 686, '令': 687, '飽': 688, '鎖': 689, '行': 690, '站': 691, '企': 692, '法': 693, '乡': 694, '须': 695, '計': 696, '择': 697, '婚': 698, '离': 699, '埋': 700, '发': 701, '许': 702, '喊': 703, '帮': 704, '鑰': 705, '惕': 706, '歌': 707, '畫': 708, '謊': 709, '自': 710, '台': 711, '感': 712, '而': 713, '歲': 714, '綠': 715, '絕': 716, '步': 717, '做': 718, '声': 719, '骚': 720, '晚': 721, '得': 722, '免': 723, '吗': 724, '飞': 725, '托': 726, '立': 727, '慌': 728, '秘': 729, '問': 730, '上': 731, '学': 732, '惧': 733, '害': 734, '辱': 735, '吃': 736, '见': 737, '谢': 738, '语': 739, '铐': 740, '掉': 741, '脚': 742, '读': 743, '敢': 744, '物': 745, '记': 746, '算': 747, '黑': 748, '继': 749, '送': 750, '弱': 751, '休': 752, '麻': 753, '果': 754, '參': 755, '遇': 756, '辆': 757, 'i': 758, '。': 759, '回': 760, '壯': 761, '幫': 762, '午': 763, '試': 764, '應': 765, '闭': 766, '席': 767, '半': 768, '余': 769, '病': 770, '走': 771, '種': 772, '左': 773, '顯': 774, '經': 775, '处': 776, '疯': 777, '浮': 778, '为': 779, '独': 780, '脱': 781, '严': 782, '真': 783, '瑪': 784, '时': 785, '赌': 786, '顾': 787, '鸡': 788, '拯': 789, '红': 790, '喜': 791, '带': 792, '察': 793, '帳': 794, '变': 795, '话': 796, '讀': 797, '.': 798, '抵': 799, '畏': 800, '跟': 801, '拉': 802, '擔': 803, '該': 804, '欺': 805, '英': 806, '画': 807, '已': 808, '这': 809, '胖': 810, '花': 811, '调': 812, '也': 813, '嫉': 814, '投': 815, '厌': 816, '旁': 817, '位': 818, '氣': 819, '欢': 820, '適': 821, '多': 822, '们': 823, '好': 824, '乎': 825, '失': 826, '子': 827, '冰': 828, '演': 829, '哦': 830, '姆': 831, '類': 832, '皺': 833, '闷': 834, '着': 835, '所': 836, '情': 837, '拜': 838, '要': 839, '撒': 840, '幹': 841, '有': 842, '船': 843, '容': 844, '设': 845, '茶': 846, '雄': 847, '贏': 848, '許': 849, '责': 850, '放': 851, '谁': 852, '抗': 853, '允': 854, '利': 855, '邪': 856, '和': 857, '須': 858, '五': 859, '錢': 860, '转': 861, '爵': 862, '樣': 863, '当': 864, '首': 865, '没': 866, '敬': 867, '的': 868, '讨': 869, '瑰': 870, '講': 871}\n"
     ]
    }
   ],
   "source": [
    "# 特殊字符\n",
    "SOURCE_CODES = ['<PAD>', '<UNK>']\n",
    "TARGET_CODES = ['<PAD>', '<EOS>', '<UNK>', '<GO>']  # 在target中，需要增加<GO>与<EOS>特殊字符\n",
    "\n",
    "# 分别生成中英文字典\n",
    "en_vocab = set(''.join(en_data))\n",
    "id2en = SOURCE_CODES + list(en_vocab)\n",
    "en2id = {c:i for i,c in enumerate(id2en)}\n",
    "\n",
    "# 分别生成中英文字典\n",
    "ch_vocab = set(''.join(ch_data))\n",
    "id2ch = TARGET_CODES + list(ch_vocab)\n",
    "ch2id = {c:i for i,c in enumerate(id2ch)}\n",
    "\n",
    "print('\\n英文字典:\\n', en2id)\n",
    "print('\\n中文字典共计\\n:', ch2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "char: Hi.\n",
      "index: [53, 63, 40]\n"
     ]
    }
   ],
   "source": [
    "# 利用字典，映射数据\n",
    "en_num_data = [[en2id[en] for en in line] for line in en_data]\n",
    "de_num_data = [[ch2id[ch] for ch in line] + [ch2id['<EOS>']] for line in ch_data]\n",
    "\n",
    "print('char:', en_data[1])\n",
    "print('index:', en_num_data[1])\n",
    "\n",
    "en_maxlength = max([len(line) for line in en_num_data])\n",
    "ch_maxlength = max([len(line) for line in de_num_data])\n",
    "\n",
    "# 文本数据转化为数字数据\n",
    "en_num_data = [data + [en2id['<PAD>']] * (en_maxlength - len(data)) for data in en_num_data]\n",
    "de_num_data = [data + [en2id['<PAD>']] * (ch_maxlength - len(data)) for data in de_num_data]\n",
    "\n",
    "\n",
    "# 设计数据生成器\n",
    "def batch_data(en_num_data, ch_num_data, de_num_data, batch_size):\n",
    "    batch_num = len(en_num_data) // batch_size\n",
    "    for i in range(batch_num):\n",
    "        begin = i * batch_size\n",
    "        end = begin + batch_size\n",
    "        x = en_num_data[begin:end]\n",
    "        z = de_num_data[begin:end]\n",
    "        yield x, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max encoder length: 9\n",
      "max decoder length: 11\n",
      "input shape: (100, 9, 46)\n",
      "output shape: (100, 11, 149)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 获取输入输出端的最大长度\n",
    "max_encoder_seq_length = max([len(txt) for txt in en_num_data])\n",
    "max_decoder_seq_length = max([len(txt) for txt in ch_num_data])\n",
    "print('max encoder length:', max_encoder_seq_length)\n",
    "print('max decoder length:', max_decoder_seq_length)\n",
    "\n",
    "# 将数据进行onehot处理\n",
    "encoder_input_data = np.zeros((len(en_num_data), max_encoder_seq_length, len(en2id)), dtype='float32')\n",
    "decoder_input_data = np.zeros((len(ch_num_data), max_decoder_seq_length, len(ch2id)), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(ch_num_data), max_decoder_seq_length, len(ch2id)), dtype='float32')\n",
    "\n",
    "for i in range(len(ch_num_data)):\n",
    "    for t, j in enumerate(en_num_data[i]):\n",
    "        encoder_input_data[i, t, j] = 1.\n",
    "    for t, j in enumerate(ch_num_data[i]):\n",
    "        decoder_input_data[i, t, j] = 1.\n",
    "    for t, j in enumerate(de_num_data[i]):\n",
    "        decoder_target_data[i, t, j] = 1.\n",
    "\n",
    "\n",
    "print('input shape:', encoder_input_data.shape)\n",
    "print('output shape:', decoder_input_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======预定义模型参数========\n",
    "EN_VOCAB_SIZE = len(en2id)\n",
    "CH_VOCAB_SIZE = len(ch2id)\n",
    "HIDDEN_SIZE = 256\n",
    "\n",
    "LEARNING_RATE = 0.003\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RNNModel():\n",
    "\t\"\"\"docstring for RNNModel\"\"\"\n",
    "\tdef __init__(self, BATCH_SIZE, HIDDEN_SIZE, HIDDEN_LAYERS, learning_rate):\n",
    "\t\tsuper(RNNModel, self).__init__()\n",
    "\t\tself.BATCH_SIZE = BATCH_SIZE\n",
    "\t\tself.HIDDEN_SIZE = HIDDEN_SIZE\n",
    "\t\tself.HIDDEN_LAYERS = HIDDEN_LAYERS\n",
    "\t\t\n",
    "\t\t# ======定义占位符======\n",
    "\t\twith tf.name_scope('input'):\n",
    "\t\t\tself.encoder_inputs = tf.placeholder(tf.float32, [BATCH_SIZE, max_encoder_seq_length, EN_VOCAB_SIZE])\n",
    "\t\t\tself.decoder_inputs = tf.placeholder(tf.float32, [BATCH_SIZE, max_decoder_seq_length, CH_VOCAB_SIZE])\n",
    "\t\t\tself.targets = tf.placeholder(tf.float32, [BATCH_SIZE, max_decoder_seq_length, None])\n",
    "\t\t\tself.keepprb = tf.placeholder(tf.float32)\n",
    "\n",
    "\t\t# ======搭建encoder结构=====\n",
    "\t\twith tf.name_scope('encoder'):\n",
    "\t\t\tlstm1 = tf.contrib.rnn.LSTMCell(HIDDEN_SIZE, state_is_tuple=True)\n",
    "\t\t\tlstm1 = tf.contrib.rnn.DropoutWrapper(lstm1, output_keep_prob=self.keepprb)\n",
    "\t\t\tcell1 = tf.contrib.rnn.MultiRNNCell([lstm1] * HIDDEN_LAYERS)\n",
    "\t\t\tinitial_state = cell1.zero_state(BATCH_SIZE, tf.float32)\n",
    "            \n",
    "\t\t\t_, self.final_state = tf.nn.dynamic_rnn(cell1, self.encoder_inputs, initial_state=initial_state)\n",
    "\n",
    "\t\t# ======搭建decoder结构=====\n",
    "\t\twith tf.name_scope('decoder'):\n",
    "\t\t\tlstm2 = tf.contrib.rnn.LSTMCell(HIDDEN_SIZE, state_is_tuple=True)\n",
    "\t\t\tlstm2 = tf.contrib.rnn.DropoutWrapper(lstm2, output_keep_prob=self.keepprb)\n",
    "\t\t\tcell2 = tf.contrib.rnn.MultiRNNCell([lstm2] * HIDDEN_LAYERS)\n",
    "\n",
    "\t\t\toutputs, self.final_state = tf.nn.dynamic_rnn(cell2, self.decoder_inputs, initial_state=self.final_state)\n",
    "            \n",
    "            \n",
    "\t\t# =====重新reshape输出=====\n",
    "\t\twith tf.name_scope('output_layer'):\n",
    "\t\t\toutputs = tf.reshape(tf.concat(outputs, 1), [-1, HIDDEN_SIZE])\n",
    "\t\t\tw = tf.get_variable('outputs_weight', [HIDDEN_SIZE, VOCAB_SIZE])\n",
    "\t\t\tb = tf.get_variable('outputs_bias', [VOCAB_SIZE])\n",
    "\t\t\tlogits = tf.matmul(outputs, w) + b\n",
    "\n",
    "\t\t# ======计算损失=======\n",
    "\t\twith tf.name_scope('loss'):\n",
    "\t\t\tself.loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example([logits], [tf.reshape(self.targets, [-1])], \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t[tf.ones([BATCH_SIZE * TIME_STEPS], dtype=tf.float32)])\n",
    "\t\t\tself.cost = tf.reduce_sum(self.loss) / BATCH_SIZE\n",
    "\n",
    "\t\t# =============优化算法==============\n",
    "\t\twith tf.name_scope('opt'):\n",
    "            # =============学习率衰减==============\n",
    "\t\t\tglobal_step = tf.Variable(0)\n",
    "\t\t\tlearning_rate = tf.train.exponential_decay(learning_rate, global_step, BATCH_NUMS, 0.99, staircase=True)\n",
    "\n",
    "\t\t\t# =======通过clip_by_global_norm()控制梯度大小======\n",
    "\t\t\ttrainable_variables = tf.trainable_variables()\n",
    "\t\t\tgrads, _ = tf.clip_by_global_norm(tf.gradients(self.cost, trainable_variables), MAX_GRAD_NORM)\n",
    "\t\t\tself.opt = tf.train.AdamOptimizer(learning_rate).apply_gradients(zip(grads, trainable_variables))\n",
    "\n",
    "\t\t# ==============预测输出=============\n",
    "\t\twith tf.name_scope('predict'):\n",
    "\t\t\tself.predict = tf.argmax(logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable rnn/multi_rnn_cell/cell_0/lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"d:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"d:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"d:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-e742a5a46d5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# ===========模型训练===========\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRNNModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHIDDEN_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHIDDEN_LAYERS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# 保存模型\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-7e14fbe124e3>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, BATCH_SIZE, HIDDEN_SIZE, HIDDEN_LAYERS, learning_rate)\u001b[0m\n\u001b[0;32m     23\u001b[0m                         \u001b[0minitial_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcell1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m                         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinal_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcell1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;31m# ======搭建decoder结构=====\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[1;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m         dtype=dtype)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[1;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    831\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 832\u001b[1;33m       swap_memory=swap_memory)\n\u001b[0m\u001b[0;32m    833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m   \u001b[1;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[1;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations)\u001b[0m\n\u001b[0;32m   3200\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mouter_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3201\u001b[0m       \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3202\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBuildLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape_invariants\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3203\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3204\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[1;34m(self, pred, body, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2938\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2939\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[1;32m-> 2940\u001b[1;33m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[0;32m   2941\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2942\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[1;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[0;32m   2875\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[0;32m   2876\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2877\u001b[1;33m     \u001b[0mbody_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2878\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2879\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(i, lv)\u001b[0m\n\u001b[0;32m   3176\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[0;32m   3177\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[1;32m-> 3178\u001b[1;33m         \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3180\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[1;34m(time, output_ta_t, state)\u001b[0m\n\u001b[0;32m    801\u001b[0m           skip_conditionals=True)\n\u001b[0;32m    802\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 803\u001b[1;33m       \u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    805\u001b[0m     \u001b[1;31m# Pack state if using state tuples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m     \u001b[0mcall_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope_attrname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    715\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m             raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, state)\u001b[0m\n\u001b[0;32m   1240\u001b[0m                                       [-1, cell.state_size])\n\u001b[0;32m   1241\u001b[0m           \u001b[0mcur_state_pos\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m         \u001b[0mcur_inp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_inp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1243\u001b[0m         \u001b[0mnew_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope)\u001b[0m\n\u001b[0;32m   1056\u001b[0m                              \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_recurrent_input_noise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1057\u001b[0m                              self._input_keep_prob)\n\u001b[1;32m-> 1058\u001b[1;33m     \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1059\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_should_dropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state_keep_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m       \u001b[1;31m# Identify which subsets of the state to perform dropout on and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[1;31m# method.  See the class docstring for more details.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m     return base_layer.Layer.__call__(self, inputs, state, scope=scope,\n\u001b[1;32m--> 298\u001b[1;33m                                      *args, **kwargs)\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    694\u001b[0m               \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m           \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m           \u001b[1;31m# Note: not all sub-classes of Layer call Layer.__init__ (especially\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, inputs_shape)\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_depth\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 726\u001b[1;33m         partitioner=maybe_partitioner)\n\u001b[0m\u001b[0;32m    727\u001b[0m     self._bias = self.add_variable(\n\u001b[0;32m    728\u001b[0m         \u001b[0m_BIAS_VARIABLE_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36madd_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner)\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 546\u001b[1;33m             partitioner=partitioner)\n\u001b[0m\u001b[0;32m    547\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minit_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    413\u001b[0m     new_variable = getter(\n\u001b[0;32m    414\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m         **kwargs_for_getter)\n\u001b[0m\u001b[0;32m    416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[1;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1295\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m       \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m       constraint=constraint)\n\u001b[0m\u001b[0;32m   1298\u001b[0m get_variable_or_local_docstring = (\n\u001b[0;32m   1299\u001b[0m     \"\"\"%s\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m   1091\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m           \u001b[0muse_resource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m           constraint=constraint)\n\u001b[0m\u001b[0;32m   1094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint)\u001b[0m\n\u001b[0;32m    429\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m\"constraint\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mestimator_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m         \u001b[0mcustom_getter_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"constraint\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 431\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m       return _true_getter(\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn_cell_impl.py\u001b[0m in \u001b[0;36m_rnn_get_variable\u001b[1;34m(self, getter, *args, **kwargs)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m     \u001b[0mvariable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m       \u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trainable\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    406\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m           use_resource=use_resource, constraint=constraint)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint)\u001b[0m\n\u001b[0;32m    745\u001b[0m                          \u001b[1;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 747\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    748\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable rnn/multi_rnn_cell/cell_0/lstm_cell/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"d:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n  File \"d:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"d:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =======预定义模型参数========\n",
    "EPOCHS = 50\n",
    "TIME_STEPS = 100\n",
    "\n",
    "HIDDEN_LAYERS = 3\n",
    "MAX_GRAD_NORM = 1\n",
    "learning_rate = 0.003\n",
    "\n",
    "\n",
    "# ===========模型训练===========\n",
    "model = RNNModel(BATCH_SIZE, HIDDEN_SIZE, HIDDEN_LAYERS, learning_rate)\n",
    "\n",
    "# 保存模型\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "\twriter = tf.summary.FileWriter('logs/tensorboard', tf.get_default_graph())\n",
    "\n",
    "\tsess.run(tf.global_variables_initializer())\n",
    "\tfor k in range(EPOCHS):\n",
    "\t\tstate = sess.run(model.initial_state)\n",
    "\t\ttrain_data = data_generator(numdata, BATCH_SIZE, TIME_STEPS)\n",
    "\t\ttotal_loss = 0.\n",
    "\t\tfor i in range(BATCH_NUMS):\n",
    "\t\t\txs, ys = next(train_data)\n",
    "\t\t\tfeed = {model.inputs: xs, model.targets: ys, model.keepprb: 0.8, model.initial_state: state}\n",
    "\t\t\tcosts, state, _ = sess.run([model.cost, model.final_state, model.opt], feed_dict=feed)\n",
    "\t\t\ttotal_loss += costs\n",
    "\t\t\tif (i+1) % 50 == 0:\n",
    "\t\t\t\tprint('epochs:', k + 1, 'iter:', i + 1, 'cost:', total_loss / i + 1)\n",
    "\n",
    "\tsaver.save(sess, './checkpoints/lstm.ckpt')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
